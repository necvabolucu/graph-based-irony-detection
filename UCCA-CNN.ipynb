{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9014,"status":"ok","timestamp":1649084568874,"user":{"displayName":"necva Bölücü","userId":"16726435691191248247"},"user_tz":-180},"id":"K3gFakXOvzs0","outputId":"61fb7f23-af3a-418c-ae12-0dd344c28691"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Collecting tokenizers!=0.11.3,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 44.5 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 52.8 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 4.1 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 60.7 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dv1d3VF2v8KH"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","from transformers import AutoTokenizer, AutoModel, BertTokenizer, BertModel\n","from google.colab import drive\n","import tensorflow as tf\n","import os\n","import sys\n","import xml.etree.ElementTree as ET\n","import glob\n","from scipy import io"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13601,"status":"ok","timestamp":1649084603636,"user":{"displayName":"necva Bölücü","userId":"16726435691191248247"},"user_tz":-180},"id":"5f5XO1UXv8Nc","outputId":"0fc9433d-c12b-4452-9bb4-dedb40b43e0f"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU: Tesla P100-PCIE-16GB\n"]}],"source":["#define device for deep learning\n","CUDA_LAUNCH_BLOCKING=1\n","\n","device_name = tf.test.gpu_device_name()\n","if device_name == '/device:GPU:0':\n","    device = torch.device(\"cuda\")\n","    print('GPU:', torch.cuda.get_device_name(0))\n","else:\n","    raise SystemError('GPU device not found')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30953,"status":"ok","timestamp":1649084639525,"user":{"displayName":"necva Bölücü","userId":"16726435691191248247"},"user_tz":-180},"id":"0Li5Lcr4v8Pz","outputId":"94424387-eb01-4742-cb50-487b4e54ae9c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# set environment as googledrive to folder \"resource\"\n","data_path =  \"/Colab Notebooks/\"\n","\n","try:\n","    drive.mount('/content/drive')\n","    data_path = \"/content/drive/MyDrive/Colab Notebooks/UCCA-CNN/\"\n","\n","except:\n","    print(\"You are not working in Colab at the moment :(\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zYmapo2ixIXO"},"outputs":[],"source":["# parameters\n","\n","seed = 42\n","\n","np.random.seed(seed)\n","node_embedding = np.random.uniform(low=0, high=1, size=(768,))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":249,"referenced_widgets":["dc23b590f15d4e4cb2dae6173c658f8a","24f5a6c6d1e14f6990e0c58eedc6e1c0","00fe672f34de43bcb44a14b377498afc","e85c40112cc84177995ba0a212654366","8a9d180f0a3d489cb762e3cb98232e05","9fc8954b6bcc4713b056316a67fdd8cb","b2319a7ed3534c3bb8e2e4d990d835ba","499cef53466a411c93538c2a4066f9ba","76a4d10b5bb34e379e9883d140ba83e4","8e9b65b2782f43f081c5d74e3f75ce43","39a67366bc9b44708ba8d6c434cbcfa7","31614fac46ae46aab4b22c3d26d12154","805d6d1a53414000a0ed0894b7df3b73","dcc808b61948467db5667ee7b5d73f60","8800da45fcd445729fd5fc90256d05ea","242166c2d0c84b6382439cd94b0bf15b","716b0b2602084c0f9f050a174a0744ba","747ec911cb3d459fb4d504f38ee6b9a7","227cf43c587048c39f03650cb6696ec2","40283eb2c93f46a089a2e7be7c7a6dcb","97a0c88f0a97456faed4dc85ad795847","b817eb0ea14544f8a777a6965a68e6f3","839ae5e7535d42c489fd7067818f5c06","20a7dd2f9de349f69ebe1d95690e434e","4031773fdd1f4f33bde290eb3a5314e0","d018eed530ef442d8e1ae8556926dc8b","e00e362af80541c4bb3c6c606c6b364d","6b5a9a81851d40aeaf2b3acf4eccd1b9","01db730fe72847ee8454f4831555db41","89a0591bf8ca4f03892d985a3df14130","f167d3a9a208405bbb274bf21469836b","c41daa65a5a54c7ca03746cee00943ec","e2ea4e4175ae4d4983ae2a2ecdc00d85","9745c85819d0494a828e0a44f41f8cec","e39053a70f534752bcd63ef40569b986","8c58a5988a754237a6c20202ff18bd00","ff26560406b74884b8c3f40c1da18bfa","121814f3a5d24dd8a6a9d9a1b46b8972","ae0182b452ba4e74bad7106d03b0a815","c10d0b1995fb4a79878428ec3751a8ef","97f2c10c38a24c8a91381e322050a464","de735948d24f4034809b1b80322215a5","da414fbce1d744f89783b681c30d5d28","c2ab27b7409748fc860e1cd1677e7ebc","99785935e59341fdbe4d0ca648bdef04","5c334ce3cfc5421ab2890eb8b264f50a","adf8dee69cc54d878391af17d7ced1d9","4c475a8871544ea998576029e7f622d5","350e7d4982bd43f5928716812dd7bcf5","f779bc80241649899e388e7469ce208a","cd44d14d1fc048bcbafd5a8f282e6893","3d666a9069ff4c55884ad8395e1a7031","7f9ad2867f464b9c9ccfe1df69ddc42d","bfe9a5d16e02420cba0672bc6c9eeb2d","0f8e04db7c6c43e693f279092e350235"]},"executionInfo":{"elapsed":22390,"status":"ok","timestamp":1649084674402,"user":{"displayName":"necva Bölücü","userId":"16726435691191248247"},"user_tz":-180},"id":"LUCN5AWvxMyH","outputId":"09ab0764-7a4a-4b99-d3f5-6ee85a688f1a"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc23b590f15d4e4cb2dae6173c658f8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31614fac46ae46aab4b22c3d26d12154"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/972k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"839ae5e7535d42c489fd7067818f5c06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.87M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9745c85819d0494a828e0a44f41f8cec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/681M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99785935e59341fdbe4d0ca648bdef04"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["# Use last four layers by default\n","layers = [-4, -3, -2, -1]\n","tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n","model = AutoModel.from_pretrained(\"bert-base-multilingual-cased\", output_hidden_states=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rdVIrIKGxDll"},"outputs":[],"source":["def get_word_idx(sent: str, word: str):\n","     return sent.split(\" \").index(word)\n"," \n"," \n","def get_hidden_states(encoded, token_ids_word, model, layers):\n","     \"\"\"Push input IDs through model. Stack and sum `layers` (last four by default).\n","        Select only those subword token outputs that belong to our word of interest\n","        and average them.\"\"\"\n","     with torch.no_grad():\n","         output = model(**encoded)\n"," \n","     # Get all hidden states\n","     states = output.hidden_states\n","     # Stack and sum all requested layers\n","     output = torch.stack([states[i] for i in layers]).sum(0).squeeze()\n","     # Only select the tokens that constitute the requested word\n","     word_tokens_output = output[token_ids_word]\n"," \n","     return word_tokens_output.mean(dim=0)\n"," \n"," \n","def get_word_vector(sent, idx, tokenizer, model, layers):\n","     \"\"\"Get a word vector by first tokenizing the input sentence, getting all token idxs\n","        that make up the word of interest, and then `get_hidden_states`.\"\"\"\n","     encoded = tokenizer.encode_plus(sent, return_tensors=\"pt\")\n","     # get all token idxs that belong to the word of interest\n","     token_ids_word = np.where(np.array(encoded.word_ids()) == idx)\n"," \n","     return get_hidden_states(encoded, token_ids_word, model, layers)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1vhB_629wuXH"},"outputs":[],"source":["def XML_processing(file):\n","  node2tag = {} # dict[node] = 'word/tag'\n","  parent2children = {} # dict[parent] = [children]\n","  parent2childrenterminal = {}\n","  maxnoode = 0\n","  sent = '' # sentence in a string\n","  tree = ET.parse(file)\n","  root = tree.getroot()\n","  for layer in root.iter('layer'):\n","    if layer.attrib['layerID'] == '0':\n","      for node in layer.iter('node'):\n","        for attribute in node.iter('attributes'):\n","          node2tag[node.attrib['ID']] = attribute.attrib['text']\n","          sent += attribute.attrib['text'] + ' '\n","    else:\n","      for node in layer.iter('node'):\n","        e = []\n","        for edge in node.iter('edge'):\n","          if edge.attrib['toID'].startswith(\"1\"):\n","              if int(edge.attrib['toID'][2::]) > maxnoode:\n","                  maxnoode = int(edge.attrib['toID'][2::])\n","              e.append(edge.attrib['toID']) \n","              parent2children[node.attrib['ID']] = e\n","          else:\n","              e.append(edge.attrib['toID']) \n","              parent2childrenterminal[node.attrib['ID']] = e              \n","          if edge.attrib['type'] != 'Terminal':\n","            node2tag[edge.attrib['toID']] = edge.attrib['type']\n","  return node2tag, parent2children, parent2childrenterminal, maxnoode, sent[0:-1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R_MIEb1dw0SH"},"outputs":[],"source":["def create_feature_matrix(sent, parent2childrenterminal, maxnoode, node_embedding):\n","\n","  #feature_matrix = []\n","  feature_matrix = np.zeros((maxnoode,768))\n","  words = sent.split()\n","  #word_embedding = node_embedding\n","  for index in range(maxnoode):\n","    key = \"1.\"+str(index+1)\n","    if key in parent2childrenterminal.keys():\n","      value = int(parent2childrenterminal[key][0][2::])-1\n","      idx = get_word_idx(sent, words[value])\n","\n","      word_embedding = get_word_vector(sent, idx, tokenizer, model, layers)\n","    else:\n","      word_embedding = node_embedding\n","    #feature_matrix.append(word_embedding)\n","    feature_matrix[index,:] = word_embedding\n","  return feature_matrix\n","\n","def adj_list_to_matrix(adj_list, n):\n","    adj_matrix = np.zeros((n,n))\n","    np.fill_diagonal(adj_matrix,0)\n","    for i in adj_list:\n","        for j in adj_list[i]:\n","            if int(j[0])!= 0:\n","              adj_matrix[int(i[2::])-1,int(j[2::])-1] = 1\n","    return adj_matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rev0yPm-v8Sv"},"outputs":[],"source":["file = data_path + \"dataset/xml/turkish/1.xml\"\n","node2tag, parent2children, parent2childrenterminal, maxnode, sent = XML_processing(file)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1198,"status":"ok","timestamp":1648540075475,"user":{"displayName":"necva Bölücü","userId":"16726435691191248247"},"user_tz":-180},"id":"H0cXlImXw0VC","outputId":"cbacdd5d-adf5-448f-fc84-ed952d6ccee8"},"outputs":[{"data":{"text/plain":["((18, 768), (18, 18))"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["adj_matrix = adj_list_to_matrix(parent2children, maxnode)\n","\n","feature_matrix = create_feature_matrix(sent, parent2childrenterminal, maxnode, node_embedding)\n","feature_matrix.shape, adj_matrix.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_I5cuAJ_ysza"},"outputs":[],"source":["tr_irony = pd.read_csv(data_path+\"dataset/raw/turkishirony.csv\")\n","tr_dict = {}\n","for item, label in enumerate(tr_irony[\"label\"]):\n","  tr_dict[int(item)] = int(label)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NLwbvbU4w0Xx"},"outputs":[],"source":["adj_all = []\n","feature_all = []\n","count = []\n","for file in glob.glob(data_path + \"dataset/xml/turkish600/*.xml\"):\n","  node2tag, parent2children, parent2childrenterminal, maxnode, sent = XML_processing(file)\n","  file_name = file.split(\"/\",-1)\n","  sent_id = int(file_name[-1].split(\".\")[0])\n","  count.append(tr_dict[int(sent_id)-1])\n","  adj_matrix = adj_list_to_matrix(parent2children, maxnode)\n","  adj_all.append(adj_matrix)\n","  feature_matrix = create_feature_matrix(sent, parent2childrenterminal, maxnode, node_embedding)\n","  feature_all.append(feature_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":323,"status":"ok","timestamp":1649085040345,"user":{"displayName":"necva Bölücü","userId":"16726435691191248247"},"user_tz":-180},"id":"1Ob3mhiexk4C","outputId":"db15ad5c-b64c-4a65-e69f-6316b977f1d5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["220"]},"metadata":{},"execution_count":12}],"source":["len(feature_all)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PcSR5oED6hkF"},"outputs":[],"source":["def spanishEncode(label):\n","  if label == 1:\n","    return \"1\"\n","  return \"0\"\n","\n","def frenchEncode(label):\n","  if label == \"figurative\":\n","    return 1\n","  return 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y6Ky6P1atIpy"},"outputs":[],"source":["def read_spanish_dataset(filename):\n","    \n","    spanish_data = pd.read_csv(filename)\n","    spanish_data[\"label\"] = spanish_data[\"IS_IRONIC\"]\n","    spanish_data[\"text\"] = spanish_data[\"MESSAGE\"]\n","    \n","    return list(spanish_data[\"text\"]), list(spanish_data[\"label\"])\n","\n","def read_french_dataset(filename):\n","    french_data_file = open(filename, \"r\", encoding=\"utf8\")\n","\n","    french_label = []\n","    french_text = []\n","\n","    for item in french_data_file.readlines():\n","        element = item.strip(\"\\n\").split(\"\\t\")\n","        text = \"\".join(element[1:-1])\n","        #french_text.append(\" \".join(WordPunctTokenizer().tokenize(text)))\n","        french_label.append(frenchEncode(element[-1]))\n","\n","    #return french_text, french_label\n","    return french_label\n","      \n","def read_english_dataset(filename):\n","    #French\n","    english_data_file = open(filename, \"r\", encoding=\"utf8\")\n","\n","    english_label = []\n","    english_text = []\n","\n","    for item in english_data_file.readlines()[1::]:\n","        element = item.strip(\"\\n\").split(\"\\t\")\n","        text = \"\".join(element[2])\n","        #english_text.append(\" \".join(WordPunctTokenizer().tokenize(text)))\n","        english_label.append(int(element[1]))\n","\n","    #return english_text, english_label\n","    return english_label\n","\n","def read_italian_dataset(filename):\n","    italian_data_file = open(filename, \"r\", encoding=\"utf8\")\n","\n","    italian_label = []\n","    italian_text = []\n","\n","    for item in italian_data_file.readlines()[1::]:\n","        element = item.strip(\"\\n\").split(\"\\t\")\n","        #italian_text.append(\" \".join(WordPunctTokenizer().tokenize(element[1])))\n","        italian_label.append(int(element[2]))\n","\n","    #return italian_text, italian_label\n","    return italian_label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QxXAw0uotLgN"},"outputs":[],"source":["english_labels = read_english_dataset(data_path + \"dataset/raw/english.txt\")\n","italian_label = read_italian_dataset(data_path + \"dataset/raw/italian.csv\")\n","french_label = read_french_dataset(data_path + \"dataset/raw/french.csv\")\n","spanish_sentences, spanish_labels = read_spanish_dataset(data_path + \"dataset/raw/spanish.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1649085057435,"user":{"displayName":"necva Bölücü","userId":"16726435691191248247"},"user_tz":-180},"id":"wovH2VIx1unT","outputId":"b5ccc796-7fc2-4a96-b3f2-b3f4e7d69f18"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["({0, 1}, {0, 1}, {0, 1}, {0, 1})"]},"metadata":{},"execution_count":16}],"source":["set(english_labels), set(italian_label), set(french_label),set(spanish_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CIDvSuOEtcxs"},"outputs":[],"source":["english_all = []\n","english_adj = []\n","for file in glob.glob(data_path + \"dataset/xml/english/*.xml\"):\n","  node2tag, parent2children, parent2childrenterminal, maxnode, sent = XML_processing(file)\n","  file_name = file.split(\"/\",-1)\n","  sent_id = int(file_name[-1].split(\".\")[0])\n","  #count.append(tr_dict[int(sent_id)-1])\n","  #print(parent2children, maxnode)\n","  adj_matrix = adj_list_to_matrix(parent2children, maxnode)\n","  english_adj.append(adj_matrix)\n","  feature_matrix = create_feature_matrix(sent, parent2childrenterminal, maxnode, node_embedding)\n","  english_all.append(feature_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":365},"id":"LVJ1yf2S9XpQ","executionInfo":{"status":"error","timestamp":1649094012527,"user_tz":-180,"elapsed":3407935,"user":{"displayName":"necva Bölücü","userId":"16726435691191248247"}},"outputId":"bae96a44-025b-48c1-9ad6-9960ee7b78b0"},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-37da6e529a4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0madj_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madj_list_to_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent2children\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mspanish_adj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mfeature_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_feature_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent2childrenterminal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mspanish_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-0fd28e545035>\u001b[0m in \u001b[0;36mcreate_feature_matrix\u001b[0;34m(sent, parent2childrenterminal, maxnoode, node_embedding)\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_word_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mword_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_word_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mword_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-95ff53602ae1>\u001b[0m in \u001b[0;36mget_word_vector\u001b[0;34m(sent, idx, tokenizer, model, layers)\u001b[0m\n\u001b[1;32m     27\u001b[0m      \u001b[0mtoken_ids_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m      \u001b[0;32mreturn\u001b[0m \u001b[0mget_hidden_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_ids_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-7-95ff53602ae1>\u001b[0m in \u001b[0;36mget_hidden_states\u001b[0;34m(encoded, token_ids_word, model, layers)\u001b[0m\n\u001b[1;32m      8\u001b[0m         and average them.\"\"\"\n\u001b[1;32m      9\u001b[0m      \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m          \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m      \u001b[0;31m# Get all hidden states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m         )\n\u001b[1;32m   1008\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    590\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m                 )\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 514\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m         )\n\u001b[1;32m    516\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2470\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["spanish_all = []\n","spanish_adj = []\n","for file in glob.glob(data_path + \"dataset/xml/spanish/*.xml\"):\n","  node2tag, parent2children, parent2childrenterminal, maxnode, sent = XML_processing(file)\n","  file_name = file.split(\"/\",-1)\n","  sent_id = int(file_name[-1].split(\".\")[0])\n","  #count.append(tr_dict[int(sent_id)-1])\n","  #print(parent2children, maxnode)\n","  adj_matrix = adj_list_to_matrix(parent2children, maxnode)\n","  spanish_adj.append(adj_matrix)\n","  feature_matrix = create_feature_matrix(sent, parent2childrenterminal, maxnode, node_embedding)\n","  spanish_all.append(feature_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VIBo-UYf9bdT","colab":{"base_uri":"https://localhost:8080/","height":365},"executionInfo":{"status":"error","timestamp":1649097304720,"user_tz":-180,"elapsed":3289369,"user":{"displayName":"necva Bölücü","userId":"16726435691191248247"}},"outputId":"6c40c004-d42a-4014-edc1-e7c082cad1c7"},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-a0d4b200469d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0madj_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madj_list_to_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent2children\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mfrench_adj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mfeature_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_feature_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent2childrenterminal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mfrench_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-0fd28e545035>\u001b[0m in \u001b[0;36mcreate_feature_matrix\u001b[0;34m(sent, parent2childrenterminal, maxnoode, node_embedding)\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_word_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mword_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_word_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mword_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-95ff53602ae1>\u001b[0m in \u001b[0;36mget_word_vector\u001b[0;34m(sent, idx, tokenizer, model, layers)\u001b[0m\n\u001b[1;32m     27\u001b[0m      \u001b[0mtoken_ids_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m      \u001b[0;32mreturn\u001b[0m \u001b[0mget_hidden_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_ids_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-7-95ff53602ae1>\u001b[0m in \u001b[0;36mget_hidden_states\u001b[0;34m(encoded, token_ids_word, model, layers)\u001b[0m\n\u001b[1;32m      8\u001b[0m         and average them.\"\"\"\n\u001b[1;32m      9\u001b[0m      \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m          \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m      \u001b[0;31m# Get all hidden states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m         )\n\u001b[1;32m   1008\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    590\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m                 )\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 514\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m         )\n\u001b[1;32m    516\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2470\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["french_all = []\n","french_adj = []\n","for file in glob.glob(data_path + \"dataset/xml/french/*.xml\"):\n","  node2tag, parent2children, parent2childrenterminal, maxnode, sent = XML_processing(file)\n","  file_name = file.split(\"/\",-1)\n","  sent_id = int(file_name[-1].split(\".\")[0])\n","  #count.append(tr_dict[int(sent_id)-1])\n","  #print(parent2children, maxnode)\n","  adj_matrix = adj_list_to_matrix(parent2children, maxnode)\n","  french_adj.append(adj_matrix)\n","  feature_matrix = create_feature_matrix(sent, parent2childrenterminal, maxnode, node_embedding)\n","  french_all.append(feature_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L7ad_eSh9e5G"},"outputs":[],"source":["italian_all = []\n","italian_adj = []\n","for file in glob.glob(data_path + \"dataset/xml/italian/*.xml\"):\n","  node2tag, parent2children, parent2childrenterminal, maxnode, sent = XML_processing(file)\n","  file_name = file.split(\"/\",-1)\n","  sent_id = int(file_name[-1].split(\".\")[0])\n","  #count.append(tr_dict[int(sent_id)-1])\n","  #print(parent2children, maxnode)\n","  adj_matrix = adj_list_to_matrix(parent2children, maxnode)\n","  italian_adj.append(adj_matrix)\n","  feature_matrix = create_feature_matrix(sent, parent2childrenterminal, maxnode, node_embedding)\n","  italian_all.append(feature_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XCZJpEdc9bnt"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":362,"status":"ok","timestamp":1649062911115,"user":{"displayName":"necva Bölücü","userId":"16726435691191248247"},"user_tz":-180},"id":"wi-qXT_bw5vS","outputId":"ac52db41-59f9-4f99-9960-56f0fdc26237"},"outputs":[{"data":{"text/plain":["3834"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["len(train_all)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w8HtOywG5B2H"},"outputs":[],"source":["io.savemat(data_path+'turkish_irony.mat', {'feature':feature_all,'adjencency':adj_all, \"label\":count})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sQO2YTGNys3B"},"outputs":[],"source":["tr_irony = io.loadmat(data_path + 'turkish.mat')\n","tr_irony600 = io.loadmat(data_path + 'turkish_irony.mat')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t7deHVLyJe6B"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.autograd as autograd\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn.utils as utils\n","import torch.optim.lr_scheduler as lr_scheduler\n","from transformers import BertTokenizer, BertModel\n","from transformers import AutoModel, AutoTokenizer\n","from sklearn.utils import shuffle\n","import tensorflow as tf\n","import os\n","import sys\n","import math\n","import random\n","import xml.etree.ElementTree as ET\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, matthews_corrcoef, confusion_matrix, classification_report, f1_score, recall_score, precision_score, accuracy_score\n","from scipy.stats import pearsonr\n","from sklearn.model_selection import KFold\n","from nltk.tokenize import WordPunctTokenizer\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X4L4AVVaITQQ"},"outputs":[],"source":["# Model hyperparameters\n","\n","RANDOM_SEED = 42\n","batch_size = 64\n","n_out = 2\n","epoch_size = 20\n","learning_rate = 0.0001\n","init_weight_decay = 0.2\n","init_clip_max_norm = 0.1\n","filter_sizes=[3,4,5,6]\n","num_filters=200\n","dropout = 0.1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ovG27JE-DmDM"},"outputs":[],"source":["# Model dataset\n","\n","class IronyDataset(Dataset):\n","  def __init__(self, split, feature, label):\n","    self.feature_array = np.array(feature)\n","    self.label_array = label\n","\n","    #print(\"len \", len(self.feature_array), \" \", len(self.label_array))\n","\n","  def __len__(self):\n","    return len(self.feature_array)\n","\n","  def __getitem__(self, idx):\n","    selected_label = int(self.label_array[idx])\n","    selected_feature = self.feature_array[idx]\n","\n","    return selected_feature, selected_label\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ly2dS6nb3HHj"},"outputs":[],"source":["def collate_fn(data):\n","  data.sort(key=lambda x: (x[0].shape[0]), reverse=True)\n","  arrays, labels = zip(*data)\n","  lengths = [(array.shape[0]) for array in arrays]\n","  longest = max(lengths)\n","  targets = np.zeros([len(arrays), max(lengths), 768])\n","  for i, cap in enumerate(arrays):\n","    end = lengths[i]\n","    array = arrays[i]\n","    new_array = np.pad(array, [((longest - end),0),(0,0)], mode='constant')\n","    targets[i,:,:] = new_array\n","  return targets, labels\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y7ao2ko6DmI4"},"outputs":[],"source":["tr_irony = io.loadmat(data_path + 'turkish.mat')\n","tr_irony600 = io.loadmat(data_path + 'turkish_irony.mat')\n","dataset = pd.DataFrame({'feature' : feature_all, 'label' : count})\n","#dataset600 = pd.DataFrame({'feature' : tr_irony600[\"feature\"], 'label' : tr_irony600[\"label\"]})\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":310,"status":"ok","timestamp":1648550486615,"user":{"displayName":"necva Bölücü","userId":"16726435691191248247"},"user_tz":-180},"id":"G5cXwhh2mISD","outputId":"0fa64448-e3b6-4284-d885-f57d69a5a257"},"outputs":[{"data":{"text/plain":["((220,), (220,))"]},"execution_count":246,"metadata":{},"output_type":"execute_result"}],"source":["dataset[\"feature\"].shape, np.array(dataset[\"label\"]).shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B9Be0DITDmN9"},"outputs":[],"source":["\n","train_feature, valid_feature, train_label, valid_label = train_test_split(feature_all, count, test_size=0.1, random_state=RANDOM_SEED)\n","#len(train_feature), len(valid_feature)\n","\n","dl_train = DataLoader(IronyDataset(\"train\", train_feature, train_label), batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n","dl_val= DataLoader(IronyDataset(\"val\", valid_feature, valid_label), batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yHgz7awOz6A0"},"outputs":[],"source":["0# cross_lingual\n","\n","dl_train = DataLoader(IronyDataset(\"train\", english_all, english_labels), batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n","dl_val= DataLoader(IronyDataset(\"val\", feature_all, count), batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ymuyh9wSDmR3"},"outputs":[],"source":["class UCCA_CNN(nn.Module):\n","  def __init__(self, filter_sizes=[3,4,5],num_filters=50, embeding_dim=768, n_out=2, dropout=0.5):\n","    super(UCCA_CNN, self).__init__()\n","    self.embedding_dim = embeding_dim\n","    self.convs =nn.ModuleList([nn.Conv1d(in_channels=self.embedding_dim,\n","                                             out_channels=num_filters,\n","                                             kernel_size=filter_size, stride=1) for filter_size in filter_sizes])\n","    self.fc1 = nn.Linear(len(filter_sizes)*num_filters, 200)\n","    self.fc2 = nn.Linear(200, n_out)\n","    self.dropout = nn.Dropout(dropout)\n","\n","  def forward(self, input_ids):\n","    x = input_ids.transpose(1,2)\n","    x_conv_list = [conv2d(x) for conv2d in self.convs]\n","\n","    x_pool_list = [(F.max_pool1d(x_conv, kernel_size=x_conv.shape[2]))\n","            for x_conv in x_conv_list]\n","\n","    x_fc = torch.cat([x_pool.squeeze(dim=2) for x_pool in x_pool_list],\n","                         dim=1)\n","    \n","    logits = self.fc1(self.dropout(x_fc))\n","    logits = self.fc2(self.dropout(logits))\n","    return logits\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":338,"status":"ok","timestamp":1649101660648,"user":{"displayName":"necva Bölücü","userId":"16726435691191248247"},"user_tz":-180},"id":"eb294V-ky7JB","outputId":"21e11ac1-1bd2-43a6-8b50-4fb6bada4da2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["UCCA_CNN(\n","  (convs): ModuleList(\n","    (0): Conv1d(768, 200, kernel_size=(3,), stride=(1,))\n","    (1): Conv1d(768, 200, kernel_size=(4,), stride=(1,))\n","    (2): Conv1d(768, 200, kernel_size=(5,), stride=(1,))\n","    (3): Conv1d(768, 200, kernel_size=(6,), stride=(1,))\n","  )\n","  (fc1): Linear(in_features=800, out_features=200, bias=True)\n","  (fc2): Linear(in_features=200, out_features=2, bias=True)\n","  (dropout): Dropout(p=0.1, inplace=False)\n",")"]},"metadata":{},"execution_count":213}],"source":["cnn_model = UCCA_CNN(filter_sizes=filter_sizes,\n","                      num_filters=num_filters,\n","                      embeding_dim=768,\n","                      n_out=2,\n","                      dropout=dropout)\n","cnn_model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2zipOZwmy5rm"},"outputs":[],"source":["optimizer = torch.optim.Adam(cnn_model.parameters(), lr=learning_rate) #, weight_decay=init_weight_decay)\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XkTpA449xvbV"},"outputs":[],"source":["def save_checkpoint(state, location):\n","\tfilepath = os.path.join(location, 'best.pth.tar')\n","\ttorch.save(state, filepath)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vb3a6V-px7Zu"},"outputs":[],"source":["def train(train_dl, model, optimizer):\n","  model.train()\n","  total_loss = 0.\n","  for batch in train_dl:\n","    tokens, label = batch\n","    tokens, label = torch.FloatTensor(tokens), torch.LongTensor(label)\n","    tokens, label = tokens.to(device).requires_grad_(), label.to(device)\n","    optimizer.zero_grad()\n","    output = model(tokens)\n","    loss = criterion(output.view(-1, n_out), label)\n","    loss.backward()\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n","    optimizer.step()\n","    total_loss += loss.item()\n","\n","  return total_loss/float(len(train_dl))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CsN1WPSRx7ch"},"outputs":[],"source":["def evaluate(model, dl):\n","  total_loss = 0\n","  prediction_list = []\n","  label_list = []\n","  model.eval()\n","  with torch.no_grad():\n","    for batch in dl:\t\t\n","      tokens, label = batch\n","      tokens, label = torch.FloatTensor(tokens), torch.LongTensor(label)\n","      tokens, label = tokens.to(device), label.to(device)\n","      output = model(tokens)\n","      loss = criterion(output.view(-1, n_out), label)\n","      total_loss += loss.item()\n","      predicted = torch.argmax(output, dim=1)\n","      prediction_list.extend(predicted.data.cpu().numpy())\n","      label_list.extend(label.data.cpu().numpy())\n","  return f1_score(label_list, prediction_list, average='macro'), total_loss,label_list,prediction_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J4z4gowux7fB"},"outputs":[],"source":["def train_and_evaluate(model, optimizer, train_dl, val_dl, test_dl=None, fold=0):\n","  best_val_acc = -999.9\n","  r_test_acc = -999.0\n","  best_label = []\n","  best_prediction = []\n","  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n","  for epoch in range(1, epoch_size+1):\n","    total_loss = train(train_dl, model, optimizer)\n","    val_acc, val_loss, label_list,prediction_list = evaluate(model, val_dl)\n","    #test_acc, test_loss = evaluate(model, test_dl)\n","    print(\"Epoch = \", epoch, \" train loss = \", total_loss, \" val_acc = \", val_acc) #, \" test_acc = \", test_acc)\n","    if val_acc > best_val_acc:\n","      save_checkpoint({'epoch': epoch , 'state_dict': model.state_dict(), 'optim_dict': optimizer.state_dict()}, location=data_path + 'result/')\n","      best_val_acc = val_acc\n","      #r_test_acc = test_acc\n","      best_label = label_list\n","      best_prediction = prediction_list\n","    scheduler.step()\n","  print(\"Best Val acc = \", best_val_acc) #, \" Test Acc = \", r_test_acc)\n","  return best_val_acc, best_label, best_prediction\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39733,"status":"ok","timestamp":1649101705290,"user":{"displayName":"necva Bölücü","userId":"16726435691191248247"},"user_tz":-180},"id":"liTmtgYwx7iI","outputId":"aedf766d-7aa0-46a9-ddf2-aaa6b8e9a086"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch =  1  train loss =  0.8328107208013534  val_acc =  0.4768253968253968\n","Epoch =  2  train loss =  0.6120959823330243  val_acc =  0.40670153436110884\n","Epoch =  3  train loss =  0.4654809206724167  val_acc =  0.4139431201236832\n","Epoch =  4  train loss =  0.31227724875013035  val_acc =  0.43829432599486073\n","Epoch =  5  train loss =  0.2081796944141388  val_acc =  0.4499938888209869\n","Epoch =  6  train loss =  0.13287362692256768  val_acc =  0.4360400444938821\n","Epoch =  7  train loss =  0.1001694181933999  val_acc =  0.42790693726498774\n","Epoch =  8  train loss =  0.06680742061386506  val_acc =  0.4419381787802841\n","Epoch =  9  train loss =  0.05313681435460846  val_acc =  0.4108993039326706\n","Epoch =  10  train loss =  0.040753544013326364  val_acc =  0.43557296963054354\n","Epoch =  11  train loss =  0.037973654363304375  val_acc =  0.46424774998228335\n","Epoch =  12  train loss =  0.029272424957404532  val_acc =  0.44948446513975066\n","Epoch =  13  train loss =  0.02417868219781667  val_acc =  0.44499845832905094\n","Epoch =  14  train loss =  0.022360466816462577  val_acc =  0.4418667967464918\n","Epoch =  15  train loss =  0.02347356132425678  val_acc =  0.42045189843931985\n","Epoch =  16  train loss =  0.016541935445275158  val_acc =  0.40556392169295397\n","Epoch =  17  train loss =  0.01514335369283799  val_acc =  0.44191814799503926\n","Epoch =  18  train loss =  0.012092106581743185  val_acc =  0.4259681913199433\n","Epoch =  19  train loss =  0.010561892908299342  val_acc =  0.43977591036414565\n","Epoch =  20  train loss =  0.008876300943666138  val_acc =  0.44403478260869567\n","Best Val acc =  0.4768253968253968\n"]}],"source":["best_val_acc, best_label, best_prediction = train_and_evaluate(cnn_model, optimizer, dl_train, dl_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WGx-Pkrz2saU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649101707468,"user_tz":-180,"elapsed":541,"user":{"displayName":"necva Bölücü","userId":"16726435691191248247"}},"outputId":"94233d56-ac7d-4c08-e18f-425a0c258a8e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.4114285714285714, 0.36, 0.48, 0.485)"]},"metadata":{},"execution_count":216}],"source":["f1_score(best_label, best_prediction), recall_score(best_label, best_prediction), precision_score(best_label, best_prediction),accuracy_score(best_label, best_prediction)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qj2tf5qzPZp0"},"outputs":[],"source":["def get_eval_report(labels, preds):\n","  mcc = matthews_corrcoef(labels, preds)\n","  tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n","  return {\n","              \"mcc\": mcc,\n","              \"tp\": tp,\n","              \"tn\": tn,\n","              \"fp\": fp,\n","              \"fn\": fn\n","          }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ju_YVnZTEWNB"},"outputs":[],"source":["def train_and_evaluate_fold():\n","  accuracy = []\n","  recall = []\n","  f1 = []\n","  precision = []\n","  best_accuracy = []\n","  label_all = []\n","  prediction_all = []\n","\n","  #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n","  k_folds = 10\n","\n","  results = {}\n","\n","  # Set fixed random number seed\n","  torch.manual_seed(42)\n","\n","  # Define the K-fold Cross Validator\n","  kfold = KFold(n_splits=k_folds, random_state=RANDOM_SEED, shuffle=True)\n","  # Start print\n","  print('--------------------------------')\n","\n","  # K-fold Cross Validation model evaluation\n","  dataset = pd.DataFrame({'feature' : feature_all, 'label' : count})\n","  #dataset = shuffle(dataset)\n","  #print(dataset)\n","  for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n","    cnn_model = UCCA_CNN(filter_sizes=filter_sizes,\n","                      num_filters=num_filters,\n","                      embeding_dim=768,\n","                      n_out=n_out,\n","                      dropout=dropout).to(device)\n","    optimizer = torch.optim.Adam(cnn_model.parameters(), lr=learning_rate) #, weight_decay=init_weight_decay)\n","\n","    \n","    \n","    train_df = dataset.iloc[train_idx]\n","\n","    valid_df = dataset.iloc[val_idx]\n","    print(fold)\n","    dl_train = DataLoader(IronyDataset(\"train\", train_df[\"feature\"].to_numpy(), list(train_df[\"label\"])), batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n","    dl_val= DataLoader(IronyDataset(\"val\", valid_df[\"feature\"].to_numpy(), list(valid_df[\"label\"])), batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n","    best_a ,label_list,prediction_list = train_and_evaluate(cnn_model, optimizer, dl_train, dl_val, fold)\n","    best_accuracy.append(best_a)\n","    label_all.extend(label_list)\n","    prediction_all.extend(prediction_list)\n","  print(np.mean(best_accuracy))\n","  return label_all, prediction_all\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33398,"status":"ok","timestamp":1648671821494,"user":{"displayName":"necva Bölücü","userId":"16726435691191248247"},"user_tz":-180},"id":"F6I9DS_yFSp8","outputId":"7e40382b-cf1c-45b4-8b55-709509b239d6"},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------------------\n","0\n","Best Val acc =  0.8166666666666667\n","1\n","Best Val acc =  1.0\n","2\n","Best Val acc =  0.9083333333333333\n","3\n","Best Val acc =  0.9536842105263159\n","4\n","Best Val acc =  0.8562091503267975\n","5\n","Best Val acc =  0.8482758620689654\n","6\n","Best Val acc =  0.725\n","7\n","Best Val acc =  0.9536842105263159\n","8\n","Best Val acc =  0.9090909090909091\n","9\n","Best Val acc =  0.905982905982906\n","0.887692724852221\n"]}],"source":["label_all, prediction_all = train_and_evaluate_fold()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1123,"status":"ok","timestamp":1648671827928,"user":{"displayName":"necva Bölücü","userId":"16726435691191248247"},"user_tz":-180},"id":"qveyWT67cI5N","outputId":"c01eb065-39ee-4bcc-f362-03d9936fd79a"},"outputs":[{"data":{"text/plain":["(0.8956521739130435,\n"," 0.9363636363636364,\n"," 0.8583333333333333,\n"," 0.8909090909090909)"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["f1_score(label_all, prediction_all), recall_score(label_all, prediction_all), precision_score(label_all, prediction_all),accuracy_score(label_all, prediction_all)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"UCCA-CNN.ipynb","provenance":[],"authorship_tag":"ABX9TyPCmQfxKPbTBG9k1DH6mf0H"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"dc23b590f15d4e4cb2dae6173c658f8a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_24f5a6c6d1e14f6990e0c58eedc6e1c0","IPY_MODEL_00fe672f34de43bcb44a14b377498afc","IPY_MODEL_e85c40112cc84177995ba0a212654366"],"layout":"IPY_MODEL_8a9d180f0a3d489cb762e3cb98232e05"}},"24f5a6c6d1e14f6990e0c58eedc6e1c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9fc8954b6bcc4713b056316a67fdd8cb","placeholder":"​","style":"IPY_MODEL_b2319a7ed3534c3bb8e2e4d990d835ba","value":"Downloading: 100%"}},"00fe672f34de43bcb44a14b377498afc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_499cef53466a411c93538c2a4066f9ba","max":29,"min":0,"orientation":"horizontal","style":"IPY_MODEL_76a4d10b5bb34e379e9883d140ba83e4","value":29}},"e85c40112cc84177995ba0a212654366":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e9b65b2782f43f081c5d74e3f75ce43","placeholder":"​","style":"IPY_MODEL_39a67366bc9b44708ba8d6c434cbcfa7","value":" 29.0/29.0 [00:00&lt;00:00, 1.00kB/s]"}},"8a9d180f0a3d489cb762e3cb98232e05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fc8954b6bcc4713b056316a67fdd8cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2319a7ed3534c3bb8e2e4d990d835ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"499cef53466a411c93538c2a4066f9ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76a4d10b5bb34e379e9883d140ba83e4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8e9b65b2782f43f081c5d74e3f75ce43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39a67366bc9b44708ba8d6c434cbcfa7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31614fac46ae46aab4b22c3d26d12154":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_805d6d1a53414000a0ed0894b7df3b73","IPY_MODEL_dcc808b61948467db5667ee7b5d73f60","IPY_MODEL_8800da45fcd445729fd5fc90256d05ea"],"layout":"IPY_MODEL_242166c2d0c84b6382439cd94b0bf15b"}},"805d6d1a53414000a0ed0894b7df3b73":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_716b0b2602084c0f9f050a174a0744ba","placeholder":"​","style":"IPY_MODEL_747ec911cb3d459fb4d504f38ee6b9a7","value":"Downloading: 100%"}},"dcc808b61948467db5667ee7b5d73f60":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_227cf43c587048c39f03650cb6696ec2","max":625,"min":0,"orientation":"horizontal","style":"IPY_MODEL_40283eb2c93f46a089a2e7be7c7a6dcb","value":625}},"8800da45fcd445729fd5fc90256d05ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97a0c88f0a97456faed4dc85ad795847","placeholder":"​","style":"IPY_MODEL_b817eb0ea14544f8a777a6965a68e6f3","value":" 625/625 [00:00&lt;00:00, 21.2kB/s]"}},"242166c2d0c84b6382439cd94b0bf15b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"716b0b2602084c0f9f050a174a0744ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"747ec911cb3d459fb4d504f38ee6b9a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"227cf43c587048c39f03650cb6696ec2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40283eb2c93f46a089a2e7be7c7a6dcb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"97a0c88f0a97456faed4dc85ad795847":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b817eb0ea14544f8a777a6965a68e6f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"839ae5e7535d42c489fd7067818f5c06":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_20a7dd2f9de349f69ebe1d95690e434e","IPY_MODEL_4031773fdd1f4f33bde290eb3a5314e0","IPY_MODEL_d018eed530ef442d8e1ae8556926dc8b"],"layout":"IPY_MODEL_e00e362af80541c4bb3c6c606c6b364d"}},"20a7dd2f9de349f69ebe1d95690e434e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b5a9a81851d40aeaf2b3acf4eccd1b9","placeholder":"​","style":"IPY_MODEL_01db730fe72847ee8454f4831555db41","value":"Downloading: 100%"}},"4031773fdd1f4f33bde290eb3a5314e0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_89a0591bf8ca4f03892d985a3df14130","max":995526,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f167d3a9a208405bbb274bf21469836b","value":995526}},"d018eed530ef442d8e1ae8556926dc8b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c41daa65a5a54c7ca03746cee00943ec","placeholder":"​","style":"IPY_MODEL_e2ea4e4175ae4d4983ae2a2ecdc00d85","value":" 972k/972k [00:00&lt;00:00, 7.43MB/s]"}},"e00e362af80541c4bb3c6c606c6b364d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b5a9a81851d40aeaf2b3acf4eccd1b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01db730fe72847ee8454f4831555db41":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89a0591bf8ca4f03892d985a3df14130":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f167d3a9a208405bbb274bf21469836b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c41daa65a5a54c7ca03746cee00943ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2ea4e4175ae4d4983ae2a2ecdc00d85":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9745c85819d0494a828e0a44f41f8cec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e39053a70f534752bcd63ef40569b986","IPY_MODEL_8c58a5988a754237a6c20202ff18bd00","IPY_MODEL_ff26560406b74884b8c3f40c1da18bfa"],"layout":"IPY_MODEL_121814f3a5d24dd8a6a9d9a1b46b8972"}},"e39053a70f534752bcd63ef40569b986":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae0182b452ba4e74bad7106d03b0a815","placeholder":"​","style":"IPY_MODEL_c10d0b1995fb4a79878428ec3751a8ef","value":"Downloading: 100%"}},"8c58a5988a754237a6c20202ff18bd00":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_97f2c10c38a24c8a91381e322050a464","max":1961828,"min":0,"orientation":"horizontal","style":"IPY_MODEL_de735948d24f4034809b1b80322215a5","value":1961828}},"ff26560406b74884b8c3f40c1da18bfa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_da414fbce1d744f89783b681c30d5d28","placeholder":"​","style":"IPY_MODEL_c2ab27b7409748fc860e1cd1677e7ebc","value":" 1.87M/1.87M [00:00&lt;00:00, 3.80MB/s]"}},"121814f3a5d24dd8a6a9d9a1b46b8972":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae0182b452ba4e74bad7106d03b0a815":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c10d0b1995fb4a79878428ec3751a8ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97f2c10c38a24c8a91381e322050a464":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de735948d24f4034809b1b80322215a5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"da414fbce1d744f89783b681c30d5d28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2ab27b7409748fc860e1cd1677e7ebc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"99785935e59341fdbe4d0ca648bdef04":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5c334ce3cfc5421ab2890eb8b264f50a","IPY_MODEL_adf8dee69cc54d878391af17d7ced1d9","IPY_MODEL_4c475a8871544ea998576029e7f622d5"],"layout":"IPY_MODEL_350e7d4982bd43f5928716812dd7bcf5"}},"5c334ce3cfc5421ab2890eb8b264f50a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f779bc80241649899e388e7469ce208a","placeholder":"​","style":"IPY_MODEL_cd44d14d1fc048bcbafd5a8f282e6893","value":"Downloading: 100%"}},"adf8dee69cc54d878391af17d7ced1d9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d666a9069ff4c55884ad8395e1a7031","max":714314041,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7f9ad2867f464b9c9ccfe1df69ddc42d","value":714314041}},"4c475a8871544ea998576029e7f622d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfe9a5d16e02420cba0672bc6c9eeb2d","placeholder":"​","style":"IPY_MODEL_0f8e04db7c6c43e693f279092e350235","value":" 681M/681M [00:17&lt;00:00, 43.4MB/s]"}},"350e7d4982bd43f5928716812dd7bcf5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f779bc80241649899e388e7469ce208a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd44d14d1fc048bcbafd5a8f282e6893":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d666a9069ff4c55884ad8395e1a7031":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f9ad2867f464b9c9ccfe1df69ddc42d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bfe9a5d16e02420cba0672bc6c9eeb2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f8e04db7c6c43e693f279092e350235":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}